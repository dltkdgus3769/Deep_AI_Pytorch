{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T01:17:21.310294Z",
     "start_time": "2025-03-21T01:15:31.664513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# ✅ 한국어 문장 예제 데이터셋\n",
    "corpus = [\n",
    "    \"나는 너를 사랑해\",\n",
    "    \"나는 코딩을 좋아해\",\n",
    "    \"너는 나를 좋아해\",\n",
    "    \"너는 파이썬을 공부해\",\n",
    "    \"우리는 인공지능을 연구해\",\n",
    "    \"딥러닝은 재미있어\",\n",
    "    \"파이썬은 강력해\",\n",
    "    \"나는 자연어처리를 공부해\",\n",
    "]\n",
    "\n",
    "# ✅ 현재 디렉토리의 JSON 파일명\n",
    "json_file = \"코로나_naver_news.json\"\n",
    "\n",
    "# ✅ 정규식: 한글과 공백만 추출\n",
    "hangul_pattern = re.compile(r\"[가-힣\\s]+\")\n",
    "\n",
    "# ✅ corpus에 JSON의 title 한글 문장 추가\n",
    "if os.path.exists(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for item in data:\n",
    "        if isinstance(item, dict) and \"title\" in item:\n",
    "            title = item[\"title\"]\n",
    "            if isinstance(title, str):\n",
    "                cleaned = \"\".join(hangul_pattern.findall(title)).strip()\n",
    "                if cleaned:\n",
    "                    corpus.append(cleaned)\n",
    "\n",
    "    print(f\"✅ 'title' 키에서 한글 문장 {len(corpus)}개가 corpus에 추가되었습니다.\")\n",
    "else:\n",
    "    print(\"❌ JSON 파일이 존재하지 않습니다.\")\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 단어 사전 만들기\n",
    "word_list = list(set(\" \".join(corpus).split()))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "idx_dict = {i: w for w, i in word_dict.items()}\n",
    "\n",
    "# ✅ 데이터셋 변환\n",
    "def make_data(corpus):\n",
    "    inputs, targets = [], []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for i in range(len(words) - 1):  # \"나는 너를\" -> \"사랑해\"\n",
    "            x = [word_dict[w] for w in words[:i+1]]\n",
    "            y = word_dict[words[i+1]]\n",
    "            inputs.append(x)\n",
    "            targets.append(y)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "inputs, targets = make_data(corpus)\n",
    "\n",
    "# ✅ 패딩 추가 (문장 길이를 맞춤)\n",
    "max_len = max(len(seq) for seq in inputs)\n",
    "inputs_padded = [seq + [0] * (max_len - len(seq)) for seq in inputs]\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# ✅ 데이터셋 및 DataLoader 생성\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = TextDataset(inputs_padded, targets)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "vocab_size = len(word_dict)  # 단어 개수\n",
    "embed_size = 10  # 임베딩 차원\n",
    "hidden_size = 16  # RNN 은닉층 크기\n",
    "num_classes = len(word_dict)  # 예측할 단어 개수\n",
    "\n",
    "\n",
    "# 2️ RNN 모델 정의\n",
    "class RNNTextModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RNNTextModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)  # 단어 임베딩\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # 마지막 시점의 RNN 출력을 사용\n",
    "        return out\n",
    "\n",
    "# ✅ 모델 생성\n",
    "model = RNNTextModel(vocab_size, embed_size, hidden_size, num_classes)\n",
    "\n",
    "# ✅ GPU 사용 가능하면 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# ✅ 손실 함수 및 최적화 함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# 3️ 모델 학습 및 저장\n",
    "num_epochs = 100\n",
    "print(\"🚀 RNN 모델 학습 시작...\")\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ✅ 모델 저장\n",
    "model_path = \"./rnn_news_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"✅ 학습된 모델이 저장되었습니다: {model_path}\")\n",
    "# 4️ 저장된 모델 불러오기\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 저장된 RNN 모델 불러오기\n",
    "def load_model(model_path, vocab_size, embed_size, hidden_size, num_classes):\n",
    "    model = RNNTextModel(vocab_size, embed_size, hidden_size, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ✅ 모델 불러오기\n",
    "loaded_model = load_model(model_path, vocab_size, embed_size, hidden_size, num_classes)\n",
    "print(\"✅ 모델이 성공적으로 불러와졌습니다!\")\n",
    "# 5️ 샘플 문장 예측 (예측 단어 및 정확도 출력)\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_next_word(model, sentence):\n",
    "    \"\"\"\n",
    "    저장된 RNN 모델을 사용하여 주어진 문장의 다음 단어를 예측하는 함수.\n",
    "    \"\"\"\n",
    "    # ✅ 입력 문장을 정수 인코딩\n",
    "    words = sentence.split()\n",
    "    input_seq = [word_dict[w] for w in words if w in word_dict]\n",
    "\n",
    "    # ✅ 패딩 추가 (길이를 맞추기 위해)\n",
    "    input_padded = input_seq + [0] * (max_len - len(input_seq))\n",
    "    input_tensor = torch.tensor([input_padded], dtype=torch.long)\n",
    "\n",
    "    # ✅ 모델 예측\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output[0], dim=0)\n",
    "        predicted_idx = torch.argmax(probabilities).item()\n",
    "        confidence = probabilities[predicted_idx].item()\n",
    "\n",
    "    predicted_word = idx_dict[predicted_idx]\n",
    "\n",
    "    print(f\"🔍 입력 문장: '{sentence}'\")\n",
    "    print(f\"📊 예측된 단어: '{predicted_word}'\")\n",
    "    print(f\"✅ 예측 확률: {confidence * 100:.2f}%\")\n",
    "\n",
    "# 🏆 샘플 문장 예측 실행\n",
    "sample_sentence = \"나는 너를\"\n",
    "predict_next_word(loaded_model, sample_sentence)"
   ],
   "id": "beef8f6de109e258",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'title' 키에서 한글 문장 808개가 corpus에 추가되었습니다.\n",
      "🚀 RNN 모델 학습 시작...\n",
      "Epoch [10/100], Loss: 7.6568\n",
      "Epoch [20/100], Loss: 6.7330\n",
      "Epoch [30/100], Loss: 6.0405\n",
      "Epoch [40/100], Loss: 7.9360\n",
      "Epoch [50/100], Loss: 8.6157\n",
      "Epoch [60/100], Loss: 8.4986\n",
      "Epoch [70/100], Loss: 8.5448\n",
      "Epoch [80/100], Loss: 8.5733\n",
      "Epoch [90/100], Loss: 8.5219\n",
      "Epoch [100/100], Loss: 8.6236\n",
      "✅ 학습된 모델이 저장되었습니다: ./rnn_news_model.pth\n",
      "✅ 모델이 성공적으로 불러와졌습니다!\n",
      "🔍 입력 문장: '나는 너를'\n",
      "📊 예측된 단어: '코로나'\n",
      "✅ 예측 확률: 3.22%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T02:29:33.542436Z",
     "start_time": "2025-03-21T02:29:33.539845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 🏆 샘플 문장 예측 실행\n",
    "sample_sentence = \"코로나 \"\n",
    "predict_next_word(loaded_model, sample_sentence)"
   ],
   "id": "7a5e4e41d0bc16a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 입력 문장: '코로나 '\n",
      "📊 예측된 단어: '코로나'\n",
      "✅ 예측 확률: 3.50%\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
